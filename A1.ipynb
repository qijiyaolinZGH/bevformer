{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    " \n",
    "train_images_idx3_ubyte_file = '/root/autodl-tmp/ML/data/MNIST/raw/train-images-idx3-ubyte'\n",
    "train_labels_idx1_ubyte_file = '/root/autodl-tmp/ML/data/MNIST/raw/train-labels-idx1-ubyte'\n",
    " \n",
    "test_images_idx3_ubyte_file = '/root/autodl-tmp/ML/data/MNIST/raw/t10k-images-idx3-ubyte'\n",
    "test_labels_idx1_ubyte_file = '/root/autodl-tmp/ML/data/MNIST/raw/t10k-labels-idx1-ubyte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_idx3_ubyte(idx3_ubyte_file):\n",
    "    bin_data = open(idx3_ubyte_file, 'rb').read()\n",
    " \n",
    "    offset = 0\n",
    "    fmt_header = '>IIII'\n",
    "    magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, offset)\n",
    "    print (\"magic:%d, count: %d, size: %d*%d\" % (magic_number, num_images, num_rows, num_cols))\n",
    " \n",
    "    image_size = num_rows * num_cols\n",
    "    offset += struct.calcsize(fmt_header)\n",
    "    fmt_image = '>' + str(image_size) + 'B'\n",
    "    images = np.empty((num_images, num_rows, num_cols))\n",
    "    for i in range(num_images):\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print(\"done %d\" % (i + 1) + \"pictures\")\n",
    "        images[i] = np.array(struct.unpack_from(fmt_image, bin_data, offset)).reshape((num_rows, num_cols))\n",
    "        offset += struct.calcsize(fmt_image)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_idx1_ubyte(idx1_ubyte_file):\n",
    "    bin_data = open(idx1_ubyte_file, 'rb').read()\n",
    " \n",
    "    offset = 0\n",
    "    fmt_header = '>ii'\n",
    "    magic_number, num_images = struct.unpack_from(fmt_header, bin_data, offset)\n",
    "    print(\"magic:%d, num_images: %d zhang\" % (magic_number, num_images))\n",
    " \n",
    "    offset += struct.calcsize(fmt_header)\n",
    "    fmt_image = '>B'\n",
    "    labels = np.empty(num_images)\n",
    "    for i in range(num_images):\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print(\"done %d\" % (i + 1) + \"zhang\")\n",
    "        labels[i] = struct.unpack_from(fmt_image, bin_data, offset)[0]\n",
    "        offset += struct.calcsize(fmt_image)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_images(idx_ubyte_file=train_images_idx3_ubyte_file):\n",
    "    return decode_idx3_ubyte(idx_ubyte_file)\n",
    " \n",
    " \n",
    "def load_train_labels(idx_ubyte_file=train_labels_idx1_ubyte_file):\n",
    "    return decode_idx1_ubyte(idx_ubyte_file)\n",
    " \n",
    " \n",
    "def load_test_images(idx_ubyte_file=test_images_idx3_ubyte_file):\n",
    "    return decode_idx3_ubyte(idx_ubyte_file)\n",
    " \n",
    " \n",
    "def load_test_labels(idx_ubyte_file=test_labels_idx1_ubyte_file):\n",
    "    return decode_idx1_ubyte(idx_ubyte_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def narmalize_data(ima):\n",
    "    a_max=np.max(ima)\n",
    "    a_min=np.min(ima)\n",
    "    for j in range(ima.shape[0]):\n",
    "        ima[j]=(ima[j]-a_min)/(a_max-a_min)\n",
    "    return ima\n",
    "def initialize_with_zeros(n_x,n_h,n_y):\n",
    "    np.random.seed(2)\n",
    "    W1=np.random.uniform(-np.sqrt(6)/np.sqrt(n_x+n_h),np.sqrt(6)/np.sqrt(n_h+n_x),size=(n_h,n_x))\n",
    "    b1=np.zeros((n_h,1))\n",
    "    W2=np.random.uniform(-np.sqrt(6)/np.sqrt(n_y+n_h),np.sqrt(6)/np.sqrt(n_y+n_h),size=(n_y,n_h))\n",
    "    b2=np.zeros((n_y,1))\n",
    " \n",
    "    assert (W1.shape == (n_h, n_x))\n",
    "    assert (b1.shape == (n_h, 1))\n",
    "    assert (W2.shape == (n_y, n_h))\n",
    "    assert (b2.shape == (n_y, 1))\n",
    " \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    " \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,parameters):\n",
    "    W1=parameters[\"W1\"]\n",
    "    b1=parameters[\"b1\"]\n",
    "    W2=parameters[\"W2\"]\n",
    "    b2=parameters[\"b2\"]\n",
    "    Z1=np.dot(W1,X)+b1\n",
    "    A1=np.tanh(Z1)\n",
    "    Z2=np.dot(W2,A1)+b2\n",
    "    A2=sigmoid(Z2)\n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    return A2, cache\n",
    " \n",
    "def costloss(A2,Y,parameters):\n",
    "    t=0.00000000001\n",
    "    logprobs=np.multiply(np.log(A2+t),Y) + np.multiply(np.log(1-A2+t),(1-Y))\n",
    "    cost=np.sum(logprobs,axis=0,keepdims=True)/A2.shape[0]\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(parameters,cache,X,Y):\n",
    "    W1=parameters[\"W1\"]\n",
    "    W2=parameters[\"W2\"]\n",
    "    A1 = cache[\"A1\"]\n",
    "    A2 = cache[\"A2\"]\n",
    "    Z1=cache[\"Z1\"]\n",
    " \n",
    "    dZ2=A2-Y\n",
    "    dW2=np.dot(dZ2,A1.T)\n",
    "    db2=np.sum(dZ2,axis=1,keepdims=True)\n",
    "    dZ1=np.dot(W2.T,dZ2)*(1-np.power(A1,2))\n",
    "    dW1=np.dot(dZ1,X.T)\n",
    "    db1=np.sum(dZ1,axis=1,keepdims=True)\n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    return grads\n",
    " \n",
    "def update_para(parameters, grads, learning_rate ):\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    dW1 = grads[\"dW1\"]\n",
    "    db1 = grads[\"db1\"]\n",
    "    dW2 = grads[\"dW2\"]\n",
    "    db2 = grads[\"db2\"]\n",
    "    W1=W1-learning_rate*dW1\n",
    "    b1=b1-learning_rate*db1\n",
    "    W2=W2-learning_rate*dW2\n",
    "    b2=b2-learning_rate*db2\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    s=1/(1+np.exp(-x))\n",
    "    return s\n",
    "def image2vector(image):\n",
    "    v=np.reshape(image,[784,1])\n",
    "    return v\n",
    "def softmax(x):\n",
    "    v=np.argmax(x)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    train_images = load_train_images()\n",
    "    train_labels = load_train_labels()\n",
    "    test_images = load_test_images()\n",
    "    test_labels = load_test_labels()\n",
    " \n",
    "    ii=0\n",
    "    n_x=28*28\n",
    "    n_h=32\n",
    "    n_y=10\n",
    "    parameters=initialize_with_zeros(n_x,n_h,n_y)\n",
    "    for i in range(50000):\n",
    "        # print('i:',i)\n",
    "        img_train=train_images[i]\n",
    "        label_train1=train_labels[i]\n",
    "        label_train=np.zeros((10,1))\n",
    "        ttt=0.001\n",
    "        if i>1000:\n",
    "            ttt=ttt*0.999\n",
    "        label_train[int(train_labels[i])]=1\n",
    "        imgvector1=image2vector(img_train)\n",
    "        imgvector=narmalize_data(imgvector1)\n",
    " \n",
    "        A2,cache=forward_propagation(imgvector,parameters)\n",
    "        pre_label=softmax(A2)\n",
    "        costl=costloss(A2,label_train,parameters)\n",
    "        grads = back_propagation(parameters, cache, imgvector, label_train)\n",
    "        parameters = update_para(parameters, grads, learning_rate = ttt)\n",
    "        grads[\"dW1\"]=0\n",
    "        grads[\"dW2\"]=0\n",
    "        grads[\"db1\"]=0\n",
    "        grads[\"db2\"]=0\n",
    "    for i in range(10000):\n",
    "        img_train=test_images[i]\n",
    "        vector_image=narmalize_data(image2vector(img_train))\n",
    "        label_trainx=test_labels[i]\n",
    "        aa2,xxx=forward_propagation(vector_image,parameters)\n",
    "        predict_value=softmax(aa2)\n",
    "        if predict_value==int(label_trainx):\n",
    "            ii=ii+1\n",
    "    print(ii/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "magic:2051, count: 60000, size: 28*28\n",
      "done 10000pictures\n",
      "done 20000pictures\n",
      "done 30000pictures\n",
      "done 40000pictures\n",
      "done 50000pictures\n",
      "done 60000pictures\n",
      "magic:2049, num_images: 60000 zhang\n",
      "done 10000zhang\n",
      "done 20000zhang\n",
      "done 30000zhang\n",
      "done 40000zhang\n",
      "done 50000zhang\n",
      "done 60000zhang\n",
      "magic:2051, count: 10000, size: 28*28\n",
      "done 10000pictures\n",
      "magic:2049, num_images: 10000 zhang\n",
      "done 10000zhang\n",
      "0.9119\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b2f94716c0b527ab4ec1edc6ca97a97b2ae714ad99700097d84d188efa58a5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
